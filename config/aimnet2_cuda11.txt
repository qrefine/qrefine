pytorch=*=*cuda11*
pytorch-cuda==11.8
cuda-python==11.8
numba
opt_einsum
requests
libblas=*=*mkl
cudatoolkit=11.8