pytorch=*=*cuda12*
pytorch-cuda==12.1
cuda-python
numba
opt_einsum
requests
libblas=*=*mkl
cuda-nvcc
cuda-nvcc-impl
cuda-nvrtc==12.*